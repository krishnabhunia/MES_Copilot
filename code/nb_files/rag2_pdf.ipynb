{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/kb/MES/MES_POC/POC/venv_kri_mes/bin/pip: /home/kb/MES_Copilot/POC/venv_kri_mes/bin/python: bad interpreter: No such file or directory\n",
      "/bin/bash: /home/kb/MES/MES_POC/POC/venv_kri_mes/bin/pip: /home/kb/MES_Copilot/POC/venv_kri_mes/bin/python: bad interpreter: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_groq\n",
    "! pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kb/MES/MES_POC/POC/venv_kri_mes/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "pdf_loader = PyMuPDFLoader(\"krishna_resume.pdf\")\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "# Split text into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "vector_store = FAISS.from_documents(texts, embeddings)\n",
    "retriever = vector_store.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"mixtral-8x7b-32768\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2\n",
    "# )\n",
    "\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant documents based on the query\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retrieve_documents` with `{'query': 'who is Krishna?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKRISHNA DIPAYAN BHUNIA \n",
      "Senior Software Engineer | Senior Data Engineer | Python Developer \n",
      "+91 865 200 7894 \n",
      " \n",
      "Github Link \n",
      "LinkedIn \n",
      " \n",
      "kri.career@gmail.com \n",
      "SUMMARY \n",
      "● Seasoned Software Engineer/Full Stack Developer with 12+ years of experience across industries like CRM, Oil & Gas, Financial, and FMCG. Over \n",
      "6 years of expertise in Python as a Data Engineer/Scientist, specializing in data engineering, analysis, and visualization.  \n",
      "● Proficient in writing clean, production-level Python code, with strong skills in Object-Oriented Programming, DSA, and relational databases. Used \n",
      "Python libraries such as NumPy, and Pandas for advanced data analysis and engineering stuff. \n",
      "● Experienced in designing software solutions using Python, C#, and back-end technologies. Adept in cloud platforms (AWS, Azure), containerization \n",
      "(Docker), and database management (SQL, No-SQL), with a strong ability to analyze algorithms and collaborate effectively. \n",
      "EDUCATION \n",
      "● M.TECH (Computer Eng. with Specialization in Software Eng.)   \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2016 – Jun 2018 \n",
      "Veermata Jijabai Technological Institute (VJTI), Mumbai \n",
      "● B.E Computer Engineering (University of Mumbai) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2008 – Jun 2012 \n",
      "TECHNICAL SKILLS \n",
      "● Languages & Frameworks: Python, NumPy, Pandas, Java, JavaScript (jQuery), MS SQL, PL-SQL, Oracle, C# (C-Sharp), Docker, Github. \n",
      "● Data Engineering & Analysis: Data Science and Data engineering processes, Data Analysis, Classification, Regression Analysis, Cluster Analysis, \n",
      "Data Visualization, Statistics, AWS (Amazon Web Services), Azure. \n",
      "● Databases: MS SQL Server (2019/2017), MySQL, MongoDB, Oracle 19c. \n",
      "● Expertise: DSA (Data Structures & Algorithms), Algorithm Analysis (Space & Time Complexity), Distributed Systems & Architecture. \n",
      "WORK EXPERIENCE & PROJECTS \n",
      "Senior Data Engineer in Capgemini \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "    Oct 2021 – Present \n",
      "Client - P&G(Procter & Gamble) - (Role - Data Engineer, Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "            \n",
      "Pune(Remote) \n",
      "● Technical Stack: Python, Pandas, NumPy, MS-SQL 2022, JSON, VS Code, Azure, Azure Pipelines, Docker, GitHub. \n",
      "● Proficient in Python for data engineering pipelines. \n",
      "● Experienced with Pandas, NumPy for data processing and analysis. \n",
      "● Skilled in client communication to gather data and project requirements. \n",
      "● Set up and configured Azure pipelines for CI/CD of data pipelines. \n",
      "● Created and optimized MS-SQL tables for efficient data storage. \n",
      "● Populated metrics to Grafana Dashboard from manufacturing data. \n",
      "● Designed ETL pipelines for data extraction from various sources. \n",
      "● Applied statistical techniques and optimization for data contextualization. \n",
      "● Delivered pipelines for leakage, defect detection, and insights. \n",
      "Key Achievement - With accommodating data from multiple sources makes it easy to contextualize data for easy analysis purposes, which improves \n",
      "the manufacturing lines are more adhered to not making defects/leakages in product manufacturing. The defects/leakages have been reduced to half \n",
      "of the previous defects identified. \n",
      "Software Engineer and Data Analyst in Larsen and Toubro Technological Services worked in Oil & Gas Domain \n",
      " \n",
      "Jan 2020 – Oct 2021 \n",
      " (Role – Data Engineer, Developer) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Vadodara \n",
      "  (Python, NumPy, Pandas, SciPy, MS SQL Server 2017, Oracle 11G and Oracle 10G, xlrd, xlwt, openpyxl (Anaconda Navigator Framework)). \n",
      "Plant Portal Data Analysis [ Covestro, IPEP (Data analytics team)] \n",
      "● Implementation for the process of Analysis (Deduplication, Data Seagration, File Reference Missing in Smart Plant portal, finding different \n",
      "equipment properties in plant portal, Different levels of data missing. Different file formats, Segregation and separation of different language \n",
      "formats, metadata, and migrated documents in smart plant portal).  \n",
      "● Used Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write with \n",
      "formatting using closedXML, OpenXML, EPPlus, Excel Data Reader. \n",
      "● Key Achievement – Computation has reduced time significantly for a large dataset and customer delivery satisfaction was achieved on-time. \n",
      "SPI (Smart Plant Integration) and SPEC [ Covestro, IPEP (Data analytics team)] \n",
      "● Data Comparison of migrating data from oracle to SQL Server. Generation of Excel Data and its comparison using EPPlus and generating reports. \n",
      "Created Custom controls and User controls, Delegation of custom and user controls, Background task and multithreading with parameterized \n",
      "arguments, async and await tasks, a comparison using multi and different primary keys also with dynamic and different key columns. Data view \n",
      "sync. Comparison checks for BLOB data and other Hash File data. \n",
      "● Implemented Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write \n",
      "with formatting using closedXML, EPPlus, ExcelDataReader and Dataset in Visual Studio. Logging facility in python and used data frames. \n",
      "● Key Achievement – With multithreading and parallel processing output time has been significantly improved by more than 90%. Worked closely \n",
      "with cross-functional teams including plant engineers, data owners and site engineers to design, build and deliver end-to end solutions to their \n",
      "individual data conversion and wrangling problems. \n",
      "Software Engineer in Quantum Mutual Fund worked in Financial Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Aug 2018 - Jan 2020 \n",
      "(Role – Full Stack Developer/ Data Engineer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumba \n",
      "Invest Online (INON) - Backend Developer \n",
      "● Developed business logic for investment in Q-MF & transaction, Re-Purchase, Redemption, Switch, New Purchase, STP, SWP, SIP. \n",
      "● Optimized backend SQL code for Investors, used to do KYC according to their citizenship with different criteria & process form in different queues. \n",
      "Software Engineer in Smart Solutions worked in CRM, FMCG  Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2013 - July 2018 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Inventory management and services - Backend Developer  \n",
      "● Capturing, managing, and maintaining inventories and managing. Assigning blocks and holding inventories. \n",
      "Graduate Engineer Trainee in Godrej & Boyce worked in CRM Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2012 - Sept 2013 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Timespan- Attendance and Leave management system, Assets management system & Drawer depository safe - Application  \n",
      "● Capturing, managing, and maintaining attendance and leaves for the employee in the company. Migrating assets and system information to \n",
      "standard format. \n",
      "CERTIFICATION AND LINKS (Recent) \n",
      "● LinkedIn & Pluralsight Certificates - #Using Python with Excel  #Data Wrangling with Pandas for Data Engineers\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retrieve_documents` with `{'query': 'Krishna'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKRISHNA DIPAYAN BHUNIA \n",
      "Senior Software Engineer | Senior Data Engineer | Python Developer \n",
      "+91 865 200 7894 \n",
      " \n",
      "Github Link \n",
      "LinkedIn \n",
      " \n",
      "kri.career@gmail.com \n",
      "SUMMARY \n",
      "● Seasoned Software Engineer/Full Stack Developer with 12+ years of experience across industries like CRM, Oil & Gas, Financial, and FMCG. Over \n",
      "6 years of expertise in Python as a Data Engineer/Scientist, specializing in data engineering, analysis, and visualization.  \n",
      "● Proficient in writing clean, production-level Python code, with strong skills in Object-Oriented Programming, DSA, and relational databases. Used \n",
      "Python libraries such as NumPy, and Pandas for advanced data analysis and engineering stuff. \n",
      "● Experienced in designing software solutions using Python, C#, and back-end technologies. Adept in cloud platforms (AWS, Azure), containerization \n",
      "(Docker), and database management (SQL, No-SQL), with a strong ability to analyze algorithms and collaborate effectively. \n",
      "EDUCATION \n",
      "● M.TECH (Computer Eng. with Specialization in Software Eng.)   \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2016 – Jun 2018 \n",
      "Veermata Jijabai Technological Institute (VJTI), Mumbai \n",
      "● B.E Computer Engineering (University of Mumbai) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2008 – Jun 2012 \n",
      "TECHNICAL SKILLS \n",
      "● Languages & Frameworks: Python, NumPy, Pandas, Java, JavaScript (jQuery), MS SQL, PL-SQL, Oracle, C# (C-Sharp), Docker, Github. \n",
      "● Data Engineering & Analysis: Data Science and Data engineering processes, Data Analysis, Classification, Regression Analysis, Cluster Analysis, \n",
      "Data Visualization, Statistics, AWS (Amazon Web Services), Azure. \n",
      "● Databases: MS SQL Server (2019/2017), MySQL, MongoDB, Oracle 19c. \n",
      "● Expertise: DSA (Data Structures & Algorithms), Algorithm Analysis (Space & Time Complexity), Distributed Systems & Architecture. \n",
      "WORK EXPERIENCE & PROJECTS \n",
      "Senior Data Engineer in Capgemini \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "    Oct 2021 – Present \n",
      "Client - P&G(Procter & Gamble) - (Role - Data Engineer, Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "            \n",
      "Pune(Remote) \n",
      "● Technical Stack: Python, Pandas, NumPy, MS-SQL 2022, JSON, VS Code, Azure, Azure Pipelines, Docker, GitHub. \n",
      "● Proficient in Python for data engineering pipelines. \n",
      "● Experienced with Pandas, NumPy for data processing and analysis. \n",
      "● Skilled in client communication to gather data and project requirements. \n",
      "● Set up and configured Azure pipelines for CI/CD of data pipelines. \n",
      "● Created and optimized MS-SQL tables for efficient data storage. \n",
      "● Populated metrics to Grafana Dashboard from manufacturing data. \n",
      "● Designed ETL pipelines for data extraction from various sources. \n",
      "● Applied statistical techniques and optimization for data contextualization. \n",
      "● Delivered pipelines for leakage, defect detection, and insights. \n",
      "Key Achievement - With accommodating data from multiple sources makes it easy to contextualize data for easy analysis purposes, which improves \n",
      "the manufacturing lines are more adhered to not making defects/leakages in product manufacturing. The defects/leakages have been reduced to half \n",
      "of the previous defects identified. \n",
      "Software Engineer and Data Analyst in Larsen and Toubro Technological Services worked in Oil & Gas Domain \n",
      " \n",
      "Jan 2020 – Oct 2021 \n",
      " (Role – Data Engineer, Developer) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Vadodara \n",
      "  (Python, NumPy, Pandas, SciPy, MS SQL Server 2017, Oracle 11G and Oracle 10G, xlrd, xlwt, openpyxl (Anaconda Navigator Framework)). \n",
      "Plant Portal Data Analysis [ Covestro, IPEP (Data analytics team)] \n",
      "● Implementation for the process of Analysis (Deduplication, Data Seagration, File Reference Missing in Smart Plant portal, finding different \n",
      "equipment properties in plant portal, Different levels of data missing. Different file formats, Segregation and separation of different language \n",
      "formats, metadata, and migrated documents in smart plant portal).  \n",
      "● Used Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write with \n",
      "formatting using closedXML, OpenXML, EPPlus, Excel Data Reader. \n",
      "● Key Achievement – Computation has reduced time significantly for a large dataset and customer delivery satisfaction was achieved on-time. \n",
      "SPI (Smart Plant Integration) and SPEC [ Covestro, IPEP (Data analytics team)] \n",
      "● Data Comparison of migrating data from oracle to SQL Server. Generation of Excel Data and its comparison using EPPlus and generating reports. \n",
      "Created Custom controls and User controls, Delegation of custom and user controls, Background task and multithreading with parameterized \n",
      "arguments, async and await tasks, a comparison using multi and different primary keys also with dynamic and different key columns. Data view \n",
      "sync. Comparison checks for BLOB data and other Hash File data. \n",
      "● Implemented Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write \n",
      "with formatting using closedXML, EPPlus, ExcelDataReader and Dataset in Visual Studio. Logging facility in python and used data frames. \n",
      "● Key Achievement – With multithreading and parallel processing output time has been significantly improved by more than 90%. Worked closely \n",
      "with cross-functional teams including plant engineers, data owners and site engineers to design, build and deliver end-to end solutions to their \n",
      "individual data conversion and wrangling problems. \n",
      "Software Engineer in Quantum Mutual Fund worked in Financial Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Aug 2018 - Jan 2020 \n",
      "(Role – Full Stack Developer/ Data Engineer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumba \n",
      "Invest Online (INON) - Backend Developer \n",
      "● Developed business logic for investment in Q-MF & transaction, Re-Purchase, Redemption, Switch, New Purchase, STP, SWP, SIP. \n",
      "● Optimized backend SQL code for Investors, used to do KYC according to their citizenship with different criteria & process form in different queues. \n",
      "Software Engineer in Smart Solutions worked in CRM, FMCG  Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2013 - July 2018 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Inventory management and services - Backend Developer  \n",
      "● Capturing, managing, and maintaining inventories and managing. Assigning blocks and holding inventories. \n",
      "Graduate Engineer Trainee in Godrej & Boyce worked in CRM Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2012 - Sept 2013 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Timespan- Attendance and Leave management system, Assets management system & Drawer depository safe - Application  \n",
      "● Capturing, managing, and maintaining attendance and leaves for the employee in the company. Migrating assets and system information to \n",
      "standard format. \n",
      "CERTIFICATION AND LINKS (Recent) \n",
      "● LinkedIn & Pluralsight Certificates - #Using Python with Excel  #Data Wrangling with Pandas for Data Engineers\u001b[0m\u001b[32;1m\u001b[1;3mKrishna Dipayan Bhunia is a seasoned software engineer and data engineer with over 12 years of experience across various industries. He has expertise in Python, data engineering, analysis, and visualization. He has worked on several projects, including data pipelines, ETL, and data visualization, and has experience with cloud platforms, containerization, and database management.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Retrieve relevant documents for: who is Krishna?',\n",
       " 'output': 'Krishna Dipayan Bhunia is a seasoned software engineer and data engineer with over 12 years of experience across various industries. He has expertise in Python, data engineering, analysis, and visualization. He has worked on several projects, including data pipelines, ETL, and data visualization, and has experience with cloud platforms, containerization, and database management.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [retrieve_documents]\n",
    "query = \"who is Krishna?\"\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": f\"Retrieve relevant documents for: {query}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retrieve_documents` with `{'query': 'In which company Krishna works?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKRISHNA DIPAYAN BHUNIA \n",
      "Senior Software Engineer | Senior Data Engineer | Python Developer \n",
      "+91 865 200 7894 \n",
      " \n",
      "Github Link \n",
      "LinkedIn \n",
      " \n",
      "kri.career@gmail.com \n",
      "SUMMARY \n",
      "● Seasoned Software Engineer/Full Stack Developer with 12+ years of experience across industries like CRM, Oil & Gas, Financial, and FMCG. Over \n",
      "6 years of expertise in Python as a Data Engineer/Scientist, specializing in data engineering, analysis, and visualization.  \n",
      "● Proficient in writing clean, production-level Python code, with strong skills in Object-Oriented Programming, DSA, and relational databases. Used \n",
      "Python libraries such as NumPy, and Pandas for advanced data analysis and engineering stuff. \n",
      "● Experienced in designing software solutions using Python, C#, and back-end technologies. Adept in cloud platforms (AWS, Azure), containerization \n",
      "(Docker), and database management (SQL, No-SQL), with a strong ability to analyze algorithms and collaborate effectively. \n",
      "EDUCATION \n",
      "● M.TECH (Computer Eng. with Specialization in Software Eng.)   \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2016 – Jun 2018 \n",
      "Veermata Jijabai Technological Institute (VJTI), Mumbai \n",
      "● B.E Computer Engineering (University of Mumbai) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2008 – Jun 2012 \n",
      "TECHNICAL SKILLS \n",
      "● Languages & Frameworks: Python, NumPy, Pandas, Java, JavaScript (jQuery), MS SQL, PL-SQL, Oracle, C# (C-Sharp), Docker, Github. \n",
      "● Data Engineering & Analysis: Data Science and Data engineering processes, Data Analysis, Classification, Regression Analysis, Cluster Analysis, \n",
      "Data Visualization, Statistics, AWS (Amazon Web Services), Azure. \n",
      "● Databases: MS SQL Server (2019/2017), MySQL, MongoDB, Oracle 19c. \n",
      "● Expertise: DSA (Data Structures & Algorithms), Algorithm Analysis (Space & Time Complexity), Distributed Systems & Architecture. \n",
      "WORK EXPERIENCE & PROJECTS \n",
      "Senior Data Engineer in Capgemini \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "    Oct 2021 – Present \n",
      "Client - P&G(Procter & Gamble) - (Role - Data Engineer, Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "            \n",
      "Pune(Remote) \n",
      "● Technical Stack: Python, Pandas, NumPy, MS-SQL 2022, JSON, VS Code, Azure, Azure Pipelines, Docker, GitHub. \n",
      "● Proficient in Python for data engineering pipelines. \n",
      "● Experienced with Pandas, NumPy for data processing and analysis. \n",
      "● Skilled in client communication to gather data and project requirements. \n",
      "● Set up and configured Azure pipelines for CI/CD of data pipelines. \n",
      "● Created and optimized MS-SQL tables for efficient data storage. \n",
      "● Populated metrics to Grafana Dashboard from manufacturing data. \n",
      "● Designed ETL pipelines for data extraction from various sources. \n",
      "● Applied statistical techniques and optimization for data contextualization. \n",
      "● Delivered pipelines for leakage, defect detection, and insights. \n",
      "Key Achievement - With accommodating data from multiple sources makes it easy to contextualize data for easy analysis purposes, which improves \n",
      "the manufacturing lines are more adhered to not making defects/leakages in product manufacturing. The defects/leakages have been reduced to half \n",
      "of the previous defects identified. \n",
      "Software Engineer and Data Analyst in Larsen and Toubro Technological Services worked in Oil & Gas Domain \n",
      " \n",
      "Jan 2020 – Oct 2021 \n",
      " (Role – Data Engineer, Developer) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Vadodara \n",
      "  (Python, NumPy, Pandas, SciPy, MS SQL Server 2017, Oracle 11G and Oracle 10G, xlrd, xlwt, openpyxl (Anaconda Navigator Framework)). \n",
      "Plant Portal Data Analysis [ Covestro, IPEP (Data analytics team)] \n",
      "● Implementation for the process of Analysis (Deduplication, Data Seagration, File Reference Missing in Smart Plant portal, finding different \n",
      "equipment properties in plant portal, Different levels of data missing. Different file formats, Segregation and separation of different language \n",
      "formats, metadata, and migrated documents in smart plant portal).  \n",
      "● Used Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write with \n",
      "formatting using closedXML, OpenXML, EPPlus, Excel Data Reader. \n",
      "● Key Achievement – Computation has reduced time significantly for a large dataset and customer delivery satisfaction was achieved on-time. \n",
      "SPI (Smart Plant Integration) and SPEC [ Covestro, IPEP (Data analytics team)] \n",
      "● Data Comparison of migrating data from oracle to SQL Server. Generation of Excel Data and its comparison using EPPlus and generating reports. \n",
      "Created Custom controls and User controls, Delegation of custom and user controls, Background task and multithreading with parameterized \n",
      "arguments, async and await tasks, a comparison using multi and different primary keys also with dynamic and different key columns. Data view \n",
      "sync. Comparison checks for BLOB data and other Hash File data. \n",
      "● Implemented Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write \n",
      "with formatting using closedXML, EPPlus, ExcelDataReader and Dataset in Visual Studio. Logging facility in python and used data frames. \n",
      "● Key Achievement – With multithreading and parallel processing output time has been significantly improved by more than 90%. Worked closely \n",
      "with cross-functional teams including plant engineers, data owners and site engineers to design, build and deliver end-to end solutions to their \n",
      "individual data conversion and wrangling problems. \n",
      "Software Engineer in Quantum Mutual Fund worked in Financial Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Aug 2018 - Jan 2020 \n",
      "(Role – Full Stack Developer/ Data Engineer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumba \n",
      "Invest Online (INON) - Backend Developer \n",
      "● Developed business logic for investment in Q-MF & transaction, Re-Purchase, Redemption, Switch, New Purchase, STP, SWP, SIP. \n",
      "● Optimized backend SQL code for Investors, used to do KYC according to their citizenship with different criteria & process form in different queues. \n",
      "Software Engineer in Smart Solutions worked in CRM, FMCG  Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2013 - July 2018 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Inventory management and services - Backend Developer  \n",
      "● Capturing, managing, and maintaining inventories and managing. Assigning blocks and holding inventories. \n",
      "Graduate Engineer Trainee in Godrej & Boyce worked in CRM Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2012 - Sept 2013 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Timespan- Attendance and Leave management system, Assets management system & Drawer depository safe - Application  \n",
      "● Capturing, managing, and maintaining attendance and leaves for the employee in the company. Migrating assets and system information to \n",
      "standard format. \n",
      "CERTIFICATION AND LINKS (Recent) \n",
      "● LinkedIn & Pluralsight Certificates - #Using Python with Excel  #Data Wrangling with Pandas for Data Engineers\u001b[0m\u001b[32;1m\u001b[1;3mTool use failed: no valid JSON object found in message content\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Retrieve relevant documents for: In which company Krishna works?',\n",
       " 'output': 'Tool use failed: no valid JSON object found in message content'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [retrieve_documents]\n",
    "query = \"In which company Krishna works?\"\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": f\"Retrieve relevant documents for: {query}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retrieve_documents` with `{'query': 'where Krishna works'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKRISHNA DIPAYAN BHUNIA \n",
      "Senior Software Engineer | Senior Data Engineer | Python Developer \n",
      "+91 865 200 7894 \n",
      " \n",
      "Github Link \n",
      "LinkedIn \n",
      " \n",
      "kri.career@gmail.com \n",
      "SUMMARY \n",
      "● Seasoned Software Engineer/Full Stack Developer with 12+ years of experience across industries like CRM, Oil & Gas, Financial, and FMCG. Over \n",
      "6 years of expertise in Python as a Data Engineer/Scientist, specializing in data engineering, analysis, and visualization.  \n",
      "● Proficient in writing clean, production-level Python code, with strong skills in Object-Oriented Programming, DSA, and relational databases. Used \n",
      "Python libraries such as NumPy, and Pandas for advanced data analysis and engineering stuff. \n",
      "● Experienced in designing software solutions using Python, C#, and back-end technologies. Adept in cloud platforms (AWS, Azure), containerization \n",
      "(Docker), and database management (SQL, No-SQL), with a strong ability to analyze algorithms and collaborate effectively. \n",
      "EDUCATION \n",
      "● M.TECH (Computer Eng. with Specialization in Software Eng.)   \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2016 – Jun 2018 \n",
      "Veermata Jijabai Technological Institute (VJTI), Mumbai \n",
      "● B.E Computer Engineering (University of Mumbai) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2008 – Jun 2012 \n",
      "TECHNICAL SKILLS \n",
      "● Languages & Frameworks: Python, NumPy, Pandas, Java, JavaScript (jQuery), MS SQL, PL-SQL, Oracle, C# (C-Sharp), Docker, Github. \n",
      "● Data Engineering & Analysis: Data Science and Data engineering processes, Data Analysis, Classification, Regression Analysis, Cluster Analysis, \n",
      "Data Visualization, Statistics, AWS (Amazon Web Services), Azure. \n",
      "● Databases: MS SQL Server (2019/2017), MySQL, MongoDB, Oracle 19c. \n",
      "● Expertise: DSA (Data Structures & Algorithms), Algorithm Analysis (Space & Time Complexity), Distributed Systems & Architecture. \n",
      "WORK EXPERIENCE & PROJECTS \n",
      "Senior Data Engineer in Capgemini \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "    Oct 2021 – Present \n",
      "Client - P&G(Procter & Gamble) - (Role - Data Engineer, Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "            \n",
      "Pune(Remote) \n",
      "● Technical Stack: Python, Pandas, NumPy, MS-SQL 2022, JSON, VS Code, Azure, Azure Pipelines, Docker, GitHub. \n",
      "● Proficient in Python for data engineering pipelines. \n",
      "● Experienced with Pandas, NumPy for data processing and analysis. \n",
      "● Skilled in client communication to gather data and project requirements. \n",
      "● Set up and configured Azure pipelines for CI/CD of data pipelines. \n",
      "● Created and optimized MS-SQL tables for efficient data storage. \n",
      "● Populated metrics to Grafana Dashboard from manufacturing data. \n",
      "● Designed ETL pipelines for data extraction from various sources. \n",
      "● Applied statistical techniques and optimization for data contextualization. \n",
      "● Delivered pipelines for leakage, defect detection, and insights. \n",
      "Key Achievement - With accommodating data from multiple sources makes it easy to contextualize data for easy analysis purposes, which improves \n",
      "the manufacturing lines are more adhered to not making defects/leakages in product manufacturing. The defects/leakages have been reduced to half \n",
      "of the previous defects identified. \n",
      "Software Engineer and Data Analyst in Larsen and Toubro Technological Services worked in Oil & Gas Domain \n",
      " \n",
      "Jan 2020 – Oct 2021 \n",
      " (Role – Data Engineer, Developer) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Vadodara \n",
      "  (Python, NumPy, Pandas, SciPy, MS SQL Server 2017, Oracle 11G and Oracle 10G, xlrd, xlwt, openpyxl (Anaconda Navigator Framework)). \n",
      "Plant Portal Data Analysis [ Covestro, IPEP (Data analytics team)] \n",
      "● Implementation for the process of Analysis (Deduplication, Data Seagration, File Reference Missing in Smart Plant portal, finding different \n",
      "equipment properties in plant portal, Different levels of data missing. Different file formats, Segregation and separation of different language \n",
      "formats, metadata, and migrated documents in smart plant portal).  \n",
      "● Used Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write with \n",
      "formatting using closedXML, OpenXML, EPPlus, Excel Data Reader. \n",
      "● Key Achievement – Computation has reduced time significantly for a large dataset and customer delivery satisfaction was achieved on-time. \n",
      "SPI (Smart Plant Integration) and SPEC [ Covestro, IPEP (Data analytics team)] \n",
      "● Data Comparison of migrating data from oracle to SQL Server. Generation of Excel Data and its comparison using EPPlus and generating reports. \n",
      "Created Custom controls and User controls, Delegation of custom and user controls, Background task and multithreading with parameterized \n",
      "arguments, async and await tasks, a comparison using multi and different primary keys also with dynamic and different key columns. Data view \n",
      "sync. Comparison checks for BLOB data and other Hash File data. \n",
      "● Implemented Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write \n",
      "with formatting using closedXML, EPPlus, ExcelDataReader and Dataset in Visual Studio. Logging facility in python and used data frames. \n",
      "● Key Achievement – With multithreading and parallel processing output time has been significantly improved by more than 90%. Worked closely \n",
      "with cross-functional teams including plant engineers, data owners and site engineers to design, build and deliver end-to end solutions to their \n",
      "individual data conversion and wrangling problems. \n",
      "Software Engineer in Quantum Mutual Fund worked in Financial Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Aug 2018 - Jan 2020 \n",
      "(Role – Full Stack Developer/ Data Engineer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumba \n",
      "Invest Online (INON) - Backend Developer \n",
      "● Developed business logic for investment in Q-MF & transaction, Re-Purchase, Redemption, Switch, New Purchase, STP, SWP, SIP. \n",
      "● Optimized backend SQL code for Investors, used to do KYC according to their citizenship with different criteria & process form in different queues. \n",
      "Software Engineer in Smart Solutions worked in CRM, FMCG  Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2013 - July 2018 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Inventory management and services - Backend Developer  \n",
      "● Capturing, managing, and maintaining inventories and managing. Assigning blocks and holding inventories. \n",
      "Graduate Engineer Trainee in Godrej & Boyce worked in CRM Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2012 - Sept 2013 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Timespan- Attendance and Leave management system, Assets management system & Drawer depository safe - Application  \n",
      "● Capturing, managing, and maintaining attendance and leaves for the employee in the company. Migrating assets and system information to \n",
      "standard format. \n",
      "CERTIFICATION AND LINKS (Recent) \n",
      "● LinkedIn & Pluralsight Certificates - #Using Python with Excel  #Data Wrangling with Pandas for Data Engineers\u001b[0m\u001b[32;1m\u001b[1;3mDwarka\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Retrieve relevant documents for: Pls answer in one word, where Krishna works?',\n",
       " 'output': 'Dwarka'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [retrieve_documents]\n",
    "query = \"Pls answer in one word, where Krishna works?\"\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": f\"Retrieve relevant documents for: {query}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retrieve_documents` with `{'query': 'where Krishna was working on 2012'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKRISHNA DIPAYAN BHUNIA \n",
      "Senior Software Engineer | Senior Data Engineer | Python Developer \n",
      "+91 865 200 7894 \n",
      " \n",
      "Github Link \n",
      "LinkedIn \n",
      " \n",
      "kri.career@gmail.com \n",
      "SUMMARY \n",
      "● Seasoned Software Engineer/Full Stack Developer with 12+ years of experience across industries like CRM, Oil & Gas, Financial, and FMCG. Over \n",
      "6 years of expertise in Python as a Data Engineer/Scientist, specializing in data engineering, analysis, and visualization.  \n",
      "● Proficient in writing clean, production-level Python code, with strong skills in Object-Oriented Programming, DSA, and relational databases. Used \n",
      "Python libraries such as NumPy, and Pandas for advanced data analysis and engineering stuff. \n",
      "● Experienced in designing software solutions using Python, C#, and back-end technologies. Adept in cloud platforms (AWS, Azure), containerization \n",
      "(Docker), and database management (SQL, No-SQL), with a strong ability to analyze algorithms and collaborate effectively. \n",
      "EDUCATION \n",
      "● M.TECH (Computer Eng. with Specialization in Software Eng.)   \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2016 – Jun 2018 \n",
      "Veermata Jijabai Technological Institute (VJTI), Mumbai \n",
      "● B.E Computer Engineering (University of Mumbai) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2008 – Jun 2012 \n",
      "TECHNICAL SKILLS \n",
      "● Languages & Frameworks: Python, NumPy, Pandas, Java, JavaScript (jQuery), MS SQL, PL-SQL, Oracle, C# (C-Sharp), Docker, Github. \n",
      "● Data Engineering & Analysis: Data Science and Data engineering processes, Data Analysis, Classification, Regression Analysis, Cluster Analysis, \n",
      "Data Visualization, Statistics, AWS (Amazon Web Services), Azure. \n",
      "● Databases: MS SQL Server (2019/2017), MySQL, MongoDB, Oracle 19c. \n",
      "● Expertise: DSA (Data Structures & Algorithms), Algorithm Analysis (Space & Time Complexity), Distributed Systems & Architecture. \n",
      "WORK EXPERIENCE & PROJECTS \n",
      "Senior Data Engineer in Capgemini \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "    Oct 2021 – Present \n",
      "Client - P&G(Procter & Gamble) - (Role - Data Engineer, Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "            \n",
      "Pune(Remote) \n",
      "● Technical Stack: Python, Pandas, NumPy, MS-SQL 2022, JSON, VS Code, Azure, Azure Pipelines, Docker, GitHub. \n",
      "● Proficient in Python for data engineering pipelines. \n",
      "● Experienced with Pandas, NumPy for data processing and analysis. \n",
      "● Skilled in client communication to gather data and project requirements. \n",
      "● Set up and configured Azure pipelines for CI/CD of data pipelines. \n",
      "● Created and optimized MS-SQL tables for efficient data storage. \n",
      "● Populated metrics to Grafana Dashboard from manufacturing data. \n",
      "● Designed ETL pipelines for data extraction from various sources. \n",
      "● Applied statistical techniques and optimization for data contextualization. \n",
      "● Delivered pipelines for leakage, defect detection, and insights. \n",
      "Key Achievement - With accommodating data from multiple sources makes it easy to contextualize data for easy analysis purposes, which improves \n",
      "the manufacturing lines are more adhered to not making defects/leakages in product manufacturing. The defects/leakages have been reduced to half \n",
      "of the previous defects identified. \n",
      "Software Engineer and Data Analyst in Larsen and Toubro Technological Services worked in Oil & Gas Domain \n",
      " \n",
      "Jan 2020 – Oct 2021 \n",
      " (Role – Data Engineer, Developer) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Vadodara \n",
      "  (Python, NumPy, Pandas, SciPy, MS SQL Server 2017, Oracle 11G and Oracle 10G, xlrd, xlwt, openpyxl (Anaconda Navigator Framework)). \n",
      "Plant Portal Data Analysis [ Covestro, IPEP (Data analytics team)] \n",
      "● Implementation for the process of Analysis (Deduplication, Data Seagration, File Reference Missing in Smart Plant portal, finding different \n",
      "equipment properties in plant portal, Different levels of data missing. Different file formats, Segregation and separation of different language \n",
      "formats, metadata, and migrated documents in smart plant portal).  \n",
      "● Used Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write with \n",
      "formatting using closedXML, OpenXML, EPPlus, Excel Data Reader. \n",
      "● Key Achievement – Computation has reduced time significantly for a large dataset and customer delivery satisfaction was achieved on-time. \n",
      "SPI (Smart Plant Integration) and SPEC [ Covestro, IPEP (Data analytics team)] \n",
      "● Data Comparison of migrating data from oracle to SQL Server. Generation of Excel Data and its comparison using EPPlus and generating reports. \n",
      "Created Custom controls and User controls, Delegation of custom and user controls, Background task and multithreading with parameterized \n",
      "arguments, async and await tasks, a comparison using multi and different primary keys also with dynamic and different key columns. Data view \n",
      "sync. Comparison checks for BLOB data and other Hash File data. \n",
      "● Implemented Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write \n",
      "with formatting using closedXML, EPPlus, ExcelDataReader and Dataset in Visual Studio. Logging facility in python and used data frames. \n",
      "● Key Achievement – With multithreading and parallel processing output time has been significantly improved by more than 90%. Worked closely \n",
      "with cross-functional teams including plant engineers, data owners and site engineers to design, build and deliver end-to end solutions to their \n",
      "individual data conversion and wrangling problems. \n",
      "Software Engineer in Quantum Mutual Fund worked in Financial Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Aug 2018 - Jan 2020 \n",
      "(Role – Full Stack Developer/ Data Engineer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumba \n",
      "Invest Online (INON) - Backend Developer \n",
      "● Developed business logic for investment in Q-MF & transaction, Re-Purchase, Redemption, Switch, New Purchase, STP, SWP, SIP. \n",
      "● Optimized backend SQL code for Investors, used to do KYC according to their citizenship with different criteria & process form in different queues. \n",
      "Software Engineer in Smart Solutions worked in CRM, FMCG  Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2013 - July 2018 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Inventory management and services - Backend Developer  \n",
      "● Capturing, managing, and maintaining inventories and managing. Assigning blocks and holding inventories. \n",
      "Graduate Engineer Trainee in Godrej & Boyce worked in CRM Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2012 - Sept 2013 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Timespan- Attendance and Leave management system, Assets management system & Drawer depository safe - Application  \n",
      "● Capturing, managing, and maintaining attendance and leaves for the employee in the company. Migrating assets and system information to \n",
      "standard format. \n",
      "CERTIFICATION AND LINKS (Recent) \n",
      "● LinkedIn & Pluralsight Certificates - #Using Python with Excel  #Data Wrangling with Pandas for Data Engineers\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retrieve_documents` with `{'query': 'where Krishna was working on 2012'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mKRISHNA DIPAYAN BHUNIA \n",
      "Senior Software Engineer | Senior Data Engineer | Python Developer \n",
      "+91 865 200 7894 \n",
      " \n",
      "Github Link \n",
      "LinkedIn \n",
      " \n",
      "kri.career@gmail.com \n",
      "SUMMARY \n",
      "● Seasoned Software Engineer/Full Stack Developer with 12+ years of experience across industries like CRM, Oil & Gas, Financial, and FMCG. Over \n",
      "6 years of expertise in Python as a Data Engineer/Scientist, specializing in data engineering, analysis, and visualization.  \n",
      "● Proficient in writing clean, production-level Python code, with strong skills in Object-Oriented Programming, DSA, and relational databases. Used \n",
      "Python libraries such as NumPy, and Pandas for advanced data analysis and engineering stuff. \n",
      "● Experienced in designing software solutions using Python, C#, and back-end technologies. Adept in cloud platforms (AWS, Azure), containerization \n",
      "(Docker), and database management (SQL, No-SQL), with a strong ability to analyze algorithms and collaborate effectively. \n",
      "EDUCATION \n",
      "● M.TECH (Computer Eng. with Specialization in Software Eng.)   \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2016 – Jun 2018 \n",
      "Veermata Jijabai Technological Institute (VJTI), Mumbai \n",
      "● B.E Computer Engineering (University of Mumbai) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Aug 2008 – Jun 2012 \n",
      "TECHNICAL SKILLS \n",
      "● Languages & Frameworks: Python, NumPy, Pandas, Java, JavaScript (jQuery), MS SQL, PL-SQL, Oracle, C# (C-Sharp), Docker, Github. \n",
      "● Data Engineering & Analysis: Data Science and Data engineering processes, Data Analysis, Classification, Regression Analysis, Cluster Analysis, \n",
      "Data Visualization, Statistics, AWS (Amazon Web Services), Azure. \n",
      "● Databases: MS SQL Server (2019/2017), MySQL, MongoDB, Oracle 19c. \n",
      "● Expertise: DSA (Data Structures & Algorithms), Algorithm Analysis (Space & Time Complexity), Distributed Systems & Architecture. \n",
      "WORK EXPERIENCE & PROJECTS \n",
      "Senior Data Engineer in Capgemini \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "    Oct 2021 – Present \n",
      "Client - P&G(Procter & Gamble) - (Role - Data Engineer, Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "            \n",
      "Pune(Remote) \n",
      "● Technical Stack: Python, Pandas, NumPy, MS-SQL 2022, JSON, VS Code, Azure, Azure Pipelines, Docker, GitHub. \n",
      "● Proficient in Python for data engineering pipelines. \n",
      "● Experienced with Pandas, NumPy for data processing and analysis. \n",
      "● Skilled in client communication to gather data and project requirements. \n",
      "● Set up and configured Azure pipelines for CI/CD of data pipelines. \n",
      "● Created and optimized MS-SQL tables for efficient data storage. \n",
      "● Populated metrics to Grafana Dashboard from manufacturing data. \n",
      "● Designed ETL pipelines for data extraction from various sources. \n",
      "● Applied statistical techniques and optimization for data contextualization. \n",
      "● Delivered pipelines for leakage, defect detection, and insights. \n",
      "Key Achievement - With accommodating data from multiple sources makes it easy to contextualize data for easy analysis purposes, which improves \n",
      "the manufacturing lines are more adhered to not making defects/leakages in product manufacturing. The defects/leakages have been reduced to half \n",
      "of the previous defects identified. \n",
      "Software Engineer and Data Analyst in Larsen and Toubro Technological Services worked in Oil & Gas Domain \n",
      " \n",
      "Jan 2020 – Oct 2021 \n",
      " (Role – Data Engineer, Developer) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Vadodara \n",
      "  (Python, NumPy, Pandas, SciPy, MS SQL Server 2017, Oracle 11G and Oracle 10G, xlrd, xlwt, openpyxl (Anaconda Navigator Framework)). \n",
      "Plant Portal Data Analysis [ Covestro, IPEP (Data analytics team)] \n",
      "● Implementation for the process of Analysis (Deduplication, Data Seagration, File Reference Missing in Smart Plant portal, finding different \n",
      "equipment properties in plant portal, Different levels of data missing. Different file formats, Segregation and separation of different language \n",
      "formats, metadata, and migrated documents in smart plant portal).  \n",
      "● Used Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write with \n",
      "formatting using closedXML, OpenXML, EPPlus, Excel Data Reader. \n",
      "● Key Achievement – Computation has reduced time significantly for a large dataset and customer delivery satisfaction was achieved on-time. \n",
      "SPI (Smart Plant Integration) and SPEC [ Covestro, IPEP (Data analytics team)] \n",
      "● Data Comparison of migrating data from oracle to SQL Server. Generation of Excel Data and its comparison using EPPlus and generating reports. \n",
      "Created Custom controls and User controls, Delegation of custom and user controls, Background task and multithreading with parameterized \n",
      "arguments, async and await tasks, a comparison using multi and different primary keys also with dynamic and different key columns. Data view \n",
      "sync. Comparison checks for BLOB data and other Hash File data. \n",
      "● Implemented Task, Thread and Parallel process and optimized codes with Singleton and Factory Design pattern. Excel dynamic read and write \n",
      "with formatting using closedXML, EPPlus, ExcelDataReader and Dataset in Visual Studio. Logging facility in python and used data frames. \n",
      "● Key Achievement – With multithreading and parallel processing output time has been significantly improved by more than 90%. Worked closely \n",
      "with cross-functional teams including plant engineers, data owners and site engineers to design, build and deliver end-to end solutions to their \n",
      "individual data conversion and wrangling problems. \n",
      "Software Engineer in Quantum Mutual Fund worked in Financial Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Aug 2018 - Jan 2020 \n",
      "(Role – Full Stack Developer/ Data Engineer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumba \n",
      "Invest Online (INON) - Backend Developer \n",
      "● Developed business logic for investment in Q-MF & transaction, Re-Purchase, Redemption, Switch, New Purchase, STP, SWP, SIP. \n",
      "● Optimized backend SQL code for Investors, used to do KYC according to their citizenship with different criteria & process form in different queues. \n",
      "Software Engineer in Smart Solutions worked in CRM, FMCG  Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2013 - July 2018 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Inventory management and services - Backend Developer  \n",
      "● Capturing, managing, and maintaining inventories and managing. Assigning blocks and holding inventories. \n",
      "Graduate Engineer Trainee in Godrej & Boyce worked in CRM Domain \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Oct 2012 - Sept 2013 \n",
      "(Role – Full Stack Developer)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "     Mumbai \n",
      "Timespan- Attendance and Leave management system, Assets management system & Drawer depository safe - Application  \n",
      "● Capturing, managing, and maintaining attendance and leaves for the employee in the company. Migrating assets and system information to \n",
      "standard format. \n",
      "CERTIFICATION AND LINKS (Recent) \n",
      "● LinkedIn & Pluralsight Certificates - #Using Python with Excel  #Data Wrangling with Pandas for Data Engineers\u001b[0m\u001b[32;1m\u001b[1;3mKrishna Dipayan Bhunia was working as a Graduate Engineer Trainee in Godrej & Boyce in the CRM domain from October 2012 to September 2013.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Retrieve relevant documents for: where Krishna was working on 2012',\n",
       " 'output': 'Krishna Dipayan Bhunia was working as a Graduate Engineer Trainee in Godrej & Boyce in the CRM domain from October 2012 to September 2013.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [retrieve_documents]\n",
    "query = \"where Krishna was working on 2012\"\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": f\"Retrieve relevant documents for: {query}\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_kri_mes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
